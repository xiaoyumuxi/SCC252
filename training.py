import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder # å¼•å…¥ LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# è®¾ç½®æ–‡ä»¶è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ å®é™…çš„æ–‡ä»¶å)
file_path = './data/Wednesday-workingHours.pcap_ISCX.csv'

print("æ­£åœ¨è¯»å–æ•°æ®...")

# 1. è¯»å– CSV æ–‡ä»¶
# engine='python' å¯ä»¥é¿å…æŸäº›æ–‡ä»¶åæˆ–æ ¼å¼å¯¼è‡´çš„è§£æé”™è¯¯
try:
    df = pd.read_csv(file_path)
    print(f"æ•°æ®è¯»å–æˆåŠŸï¼ŒåŸå§‹å½¢çŠ¶: {df.shape}")
except FileNotFoundError:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    exit()

# --- æ•°æ®æ¸…ç†é¢„å¤‡æ­¥éª¤ ---
# CICIDS2017 æ•°æ®é›†çš„ä¸€ä¸ªå¸¸è§é—®é¢˜æ˜¯åˆ—åå‘¨å›´æœ‰ç©ºæ ¼ï¼ˆä¾‹å¦‚ " Label" è€Œä¸æ˜¯ "Label"ï¼‰
# è¿™è¡Œä»£ç ä¼šå»é™¤æ‰€æœ‰åˆ—åé¦–å°¾çš„ç©ºæ ¼ï¼Œé˜²æ­¢åé¢æŠ¥é”™
df.columns = df.columns.str.strip()

# 2. æ¸…ç†æ•°æ® (åˆ é™¤åŒ…å« NaN æˆ– Infinity çš„è¡Œ)
print("æ­£åœ¨æ¸…ç†æ•°æ®...")

# å°†æ— ç©·å¤§ (inf) å’Œè´Ÿæ— ç©·å¤§ (-inf) æ›¿æ¢ä¸º NaN (ç©ºå€¼)
# è¿™ä¸€æ­¥éå¸¸é‡è¦ï¼Œå› ä¸ºç½‘ç»œæµé‡æ•°æ®ä¸­å¸¸å› é™¤ä»¥é›¶å‡ºç°æ— ç©·å¤§å€¼
df.replace([np.inf, -np.inf], np.nan, inplace=True)

# åˆ é™¤åŒ…å« NaN çš„è¡Œ
df.dropna(inplace=True)

print(f"æ¸…ç†åå½¢çŠ¶: {df.shape}")

# --- 3. å¤šåˆ†ç±»æ ‡ç­¾ç¼–ç  ---
print("æ­£åœ¨è¿›è¡Œå¤šåˆ†ç±»æ ‡ç­¾ç¼–ç ...")

# æŸ¥çœ‹ä¸€ä¸‹åŸå§‹çš„æ ‡ç­¾éƒ½æœ‰å“ªäº›
print("åŸå§‹æ ‡ç­¾ç±»åˆ«:", df['Label'].unique())

# ä½¿ç”¨ LabelEncoder å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸º 0, 1, 2, 3...
le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])

# ã€å…³é”®æ­¥éª¤ã€‘ä¿å­˜æ˜ å°„å…³ç³»ï¼Œæ–¹ä¾¿ä»¥åæŸ¥çœ‹å“ªä¸ªæ•°å­—ä»£è¡¨å“ªç§æ”»å‡»
#è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œå¦åˆ™è®­ç»ƒå®Œä½ ä¼šå¿˜äº† "2" åˆ°åº•ä»£è¡¨ DDoS è¿˜æ˜¯ Bot
label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("\næ ‡ç­¾æ˜ å°„å…³ç³»:")
for label, num in label_mapping.items():
    print(f"  {label} -> {num}")

# æŸ¥çœ‹ç¼–ç åçš„åˆ†å¸ƒ
print("\nç¼–ç åçš„æ ‡ç­¾åˆ†å¸ƒ:")
print(df['Label'].value_counts())

# 4. åˆ†ç¦»ç‰¹å¾ (X) å’Œ æ ‡ç­¾ (y)
y = df['Label']
X = df.drop('Label', axis=1)

# 5. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# ã€é‡è¦ä¿®æ”¹ã€‘å¢åŠ  stratify=y
# åŸå› ï¼šç½‘ç»œæµé‡æ•°æ®é€šå¸¸æåº¦ä¸å¹³è¡¡ï¼ˆæ­£å¸¸æµé‡å¾ˆå¤šï¼ŒæŸäº›æ”»å‡»å¾ˆå°‘ï¼‰ã€‚
# stratify=y ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ï¼Œå„ç±»æ”»å‡»çš„æ¯”ä¾‹ä¿æŒä¸€è‡´ï¼Œ
# é¿å…å‡ºç°æµ‹è¯•é›†ä¸­æŸç§ç½•è§æ”»å‡»å®Œå…¨æ²¡å‡ºç°çš„æƒ…å†µã€‚
print("\næ­£åœ¨åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (Stratified)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # ä¿è¯åˆ‡åˆ†åçš„ç±»åˆ«æ¯”ä¾‹ä¸åŸå§‹æ•°æ®ä¸€è‡´
)

# 6. ç‰¹å¾ç¼©æ”¾ (StandardScaler) - ä¸ä¹‹å‰ç›¸åŒ
print("æ­£åœ¨è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–...")
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("\nå¤šåˆ†ç±»é¢„å¤„ç†å®Œæˆï¼")
print("ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆã€‚")

# --- 5. æ¨¡å‹è®­ç»ƒ ---
print("\n--- æ­¥éª¤ 5: è®­ç»ƒå†³ç­–æ ‘åˆ†ç±»å™¨ (Decision Tree) ---")

# å®ä¾‹åŒ–æ¨¡å‹
dt_model = DecisionTreeClassifier(random_state=42)

# åœ¨ç¼©æ”¾åçš„è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒ
dt_model.fit(X_train, y_train)

print("æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# --- 6. æ¨¡å‹è¯„ä¼° ---
print("\n--- æ­¥éª¤ 6: æ¨¡å‹è¯„ä¼° ---")

# ä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
y_pred = dt_model.predict(X_test)

# æ‰“å°æ•´ä½“å‡†ç¡®ç‡
print(f"æµ‹è¯•é›†æ•´ä½“å‡†ç¡®ç‡: {accuracy_score(y_test, y_pred):.4f}")

# æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š (æ³¨æ„ F1-Score å¯¹äºç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æ›´é‡è¦)
print("\n--- å¤šåˆ†ç±»è¯¦ç»†è¯„ä¼°æŠ¥å‘Š ---")
# target_names ä¼ å…¥åŸå§‹æ ‡ç­¾åï¼Œè®©æŠ¥å‘Šæ›´æ˜“è¯»
print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))

# --- 7. æ¨¡å‹å’Œé¢„å¤„ç†å™¨ä¿å­˜ ---
print("\n--- æ­¥éª¤ 7: æ¨¡å‹å’Œé¢„å¤„ç†å™¨ä¿å­˜ ---")

# å®šä¹‰ä¿å­˜æ–‡ä»¶å
model_filename = './models/ids_decision_tree_model.joblib'
scaler_filename = './models/ids_standard_scaler.joblib'
encoder_filename = './models/ids_label_encoder.joblib'

# ä½¿ç”¨ joblib ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé¢„å¤„ç†å™¨
joblib.dump(dt_model, model_filename)
joblib.dump(scaler, scaler_filename)
joblib.dump(le, encoder_filename)

print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
print(f"æ¨¡å‹å’Œé¢„å¤„ç†å™¨å·²ä¿å­˜ä¸º:\n- æ¨¡å‹: {model_filename}\n- ç¼©æ”¾å™¨: {scaler_filename}\n- ç¼–ç å™¨: {encoder_filename}")
