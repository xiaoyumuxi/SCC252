import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score

# è®¾ç½®æ–‡ä»¶è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ å®é™…çš„æ–‡ä»¶å)
file_path = './data/Wednesday-workingHours.pcap_ISCX.csv'

print("æ­£åœ¨è¯»å–æ•°æ®...")

# 1. è¯»å– CSV æ–‡ä»¶
try:
    df = pd.read_csv(file_path)
    print(f"æ•°æ®è¯»å–æˆåŠŸï¼ŒåŸå§‹å½¢çŠ¶: {df.shape}")
except FileNotFoundError:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    exit()

# --- æ•°æ®æ¸…ç†é¢„å¤‡æ­¥éª¤ ---
df.columns = df.columns.str.strip()

# 2. æ¸…ç†æ•°æ® (åˆ é™¤åŒ…å« NaN æˆ– Infinity çš„è¡Œ)
print("æ­£åœ¨æ¸…ç†æ•°æ®...")

# å°†æ— ç©·å¤§ (inf) å’Œè´Ÿæ— ç©·å¤§ (-inf) æ›¿æ¢ä¸º NaN (ç©ºå€¼)
df.replace([np.inf, -np.inf], np.nan, inplace=True)

# åˆ é™¤åŒ…å« NaN çš„è¡Œ
df.dropna(inplace=True)

print(f"æ¸…ç†åå½¢çŠ¶: {df.shape}")

# --- 3. å¤šåˆ†ç±»æ ‡ç­¾ç¼–ç  ---
print("æ­£åœ¨è¿›è¡Œå¤šåˆ†ç±»æ ‡ç­¾ç¼–ç ...")

# æŸ¥çœ‹ä¸€ä¸‹åŸå§‹çš„æ ‡ç­¾éƒ½æœ‰å“ªäº›
print("åŸå§‹æ ‡ç­¾ç±»åˆ«:", df['Label'].unique())

# ä½¿ç”¨ LabelEncoder å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸º 0, 1, 2, 3...
le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])

# ã€å…³é”®æ­¥éª¤ã€‘ä¿å­˜æ˜ å°„å…³ç³»
label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("\næ ‡ç­¾æ˜ å°„å…³ç³»:")
for label, num in label_mapping.items():
    print(f"  {label} -> {num}")

# æŸ¥çœ‹ç¼–ç åçš„åˆ†å¸ƒ
print("\nç¼–ç åçš„æ ‡ç­¾åˆ†å¸ƒ:")
print(df['Label'].value_counts())

# 4. åˆ†ç¦»ç‰¹å¾ (X) å’Œ æ ‡ç­¾ (y)
y = df['Label']
X = df.drop('Label', axis=1)

# ã€å…³é”®æ–°å¢ã€‘æ•è·å¹¶ä¿å­˜ç‰¹å¾é¡ºåºï¼Œä»¥ä¾› API ç¡®ä¿è¾“å…¥æ•°æ®åˆ—é¡ºåºä¸€è‡´
FEATURE_COLUMNS = X.columns.tolist()

# 5. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
print("\næ­£åœ¨åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (Stratified)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # ä¿è¯åˆ‡åˆ†åçš„ç±»åˆ«æ¯”ä¾‹ä¸åŸå§‹æ•°æ®ä¸€è‡´
)

# 6. ç‰¹å¾ç¼©æ”¾ (StandardScaler)
print("æ­£åœ¨è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–...")
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("\nå¤šåˆ†ç±»é¢„å¤„ç†å®Œæˆï¼")
print("ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆã€‚")

#
# --- 5. æ¨¡å‹è®­ç»ƒ ---
print("\n--- æ­¥éª¤ 5: è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨ (Random Forest) ---")

# å®ä¾‹åŒ–æ¨¡å‹ - **è¿™é‡Œæ˜¯å…³é”®ä¿®æ”¹ï¼** ä½¿ç”¨ RandomForestClassifier
# n_estimators=100 è¡¨ç¤ºä½¿ç”¨ 100 æ£µå†³ç­–æ ‘
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)

# åœ¨ç¼©æ”¾åçš„è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒ
rf_model.fit(X_train, y_train)

print("æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# --- 6. æ¨¡å‹è¯„ä¼° ---
print("\n--- æ­¥éª¤ 6: æ¨¡å‹è¯„ä¼° ---")

# ä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
# ä½¿ç”¨ weighted average ä»¥é€‚åº”å¤šåˆ†ç±»å’Œå¯èƒ½çš„ä¸å¹³è¡¡æ•°æ®
precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

# æ‰“å°æ•´ä½“å‡†ç¡®ç‡
print(f"æµ‹è¯•é›†æ•´ä½“å‡†ç¡®ç‡: {accuracy:.4f}")
print(f"æµ‹è¯•é›†ç²¾ç¡®åº¦: {precision:.4f}")
print(f"æµ‹è¯•é›†å¬å›ç‡: {recall:.4f}")
print(f"æµ‹è¯•é›† F1-Score: {f1:.4f}")

# æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
print("\n--- å¤šåˆ†ç±»è¯¦ç»†è¯„ä¼°æŠ¥å‘Š ---")
print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))

# --- 7. æ¨¡å‹å’Œé¢„å¤„ç†å™¨ä¿å­˜ ---
print("\n--- æ­¥éª¤ 7: æ¨¡å‹å’Œé¢„å¤„ç†å™¨ä¿å­˜ ---")

# **ä¿ç•™åŸå§‹å†³ç­–æ ‘çš„æ–‡ä»¶åï¼Œä»¥ç¡®ä¿ API å…¼å®¹æ€§**
# æ‚¨çš„ API ä»ç„¶ä¼šåŠ è½½åä¸º ids_decision_tree_model.joblib çš„æ–‡ä»¶ï¼Œ
# ä½†å®é™…ä¸Šå®ƒæ˜¯ä¸€ä¸ªéšæœºæ£®æ—æ¨¡å‹ã€‚
model_filename = './models/ddos_rf_model.joblib'
scaler_filename = './models/ddos_scaler.joblib'
encoder_filename = './models/ddos_label_encoder.joblib'
feature_col = './models/ddos_feature_columns.joblib'

# ä½¿ç”¨ joblib ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ (rf_model) å’Œé¢„å¤„ç†å™¨
joblib.dump(rf_model, model_filename)
joblib.dump(scaler, scaler_filename)
joblib.dump(le, encoder_filename)
joblib.dump(FEATURE_COLUMNS, feature_col)

print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
print(f"æ¨¡å‹å’Œé¢„å¤„ç†å™¨å·²ä¿å­˜ä¸º:\n- æ¨¡å‹: {model_filename} (å†…å®¹ä¸ºéšæœºæ£®æ—)\n- ç¼©æ”¾å™¨: {scaler_filename}\n- ç¼–ç å™¨: {encoder_filename}")