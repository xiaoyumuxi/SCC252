import pandas as pd
import numpy as np
import joblib

# ----------------------------------------------------------------------
# 1. åŠ è½½æ‰€æœ‰ä¿å­˜çš„ç»„ä»¶
# ----------------------------------------------------------------------
try:
    # åŠ è½½æ¨¡å‹ã€ç¼©æ”¾å™¨ã€æ ‡ç­¾ç¼–ç å™¨å’Œç‰¹å¾é¡ºåº
    MODEL = joblib.load('ddos_rf_model.joblib')
    SCALER = joblib.load('ddos_scaler.joblib')
    LE = joblib.load('ddos_label_encoder.joblib')
    FEATURE_COLUMNS = joblib.load('ddos_feature_columns.joblib')
    print("æ¨¡å‹ç»„ä»¶åŠ è½½æˆåŠŸï¼Œå‡†å¤‡å°±ç»ªã€‚")
except FileNotFoundError:
    print("é”™è¯¯ï¼šæ— æ³•åŠ è½½æ¨¡å‹æ–‡ä»¶ã€‚è¯·ç¡®ä¿å·²è¿è¡Œ 'train_and_save.py' è„šæœ¬ã€‚")
    exit()


# ----------------------------------------------------------------------
# 2. æ ¸å¿ƒé¢„æµ‹å‡½æ•°
# ----------------------------------------------------------------------
def get_prediction(raw_input_data: list) -> dict:
    """
    å¯¹ä¸€ç»„æ–°çš„åŸå§‹æ•°æ®è¿›è¡Œé¢„å¤„ç†å’Œé¢„æµ‹ã€‚

    å‚æ•°:
        raw_input_data: åŒ…å« 78 ä¸ªç‰¹å¾å€¼çš„åˆ—è¡¨ï¼Œé¡ºåºå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ã€‚

    è¿”å›:
        åŒ…å«é¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦çš„å­—å…¸ã€‚
    """

    # æ£€æŸ¥è¾“å…¥æ•°æ®é•¿åº¦
    if len(raw_input_data) != len(FEATURE_COLUMNS):
        return {
            "status": "error",
            "message": f"è¾“å…¥ç‰¹å¾æ•°é‡é”™è¯¯ã€‚éœ€è¦ {len(FEATURE_COLUMNS)} ä¸ªç‰¹å¾ï¼Œä½†æ¥æ”¶åˆ° {len(raw_input_data)} ä¸ªã€‚"
        }

    # è½¬æ¢ä¸º DataFrame (å¿…é¡»ä¿æŒåˆ—é¡ºåº)
    new_df = pd.DataFrame([raw_input_data], columns=FEATURE_COLUMNS)

    # 1. æ¸…æ´— (å¤„ç†NaN/Inf)
    # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œéœ€è¦ç”¨è®­ç»ƒé›†çš„ä¸­ä½æ•°å’Œmax/minè¿›è¡Œå¡«å……å’Œæ›¿æ¢ã€‚
    # ä¸ºç®€åŒ–ï¼Œè¿™é‡Œç”¨ 0 å¡«å…… NaN/Infï¼Œå‡è®¾è¾“å…¥æ•°æ®å¤§éƒ¨åˆ†æ˜¯æ•°å€¼ã€‚
    new_df.replace([np.inf, -np.inf], np.nan, inplace=True)
    new_df.fillna(0, inplace=True)

    # 2. ç‰¹å¾ç¼©æ”¾ (å…³é”®æ­¥éª¤ï¼šä½¿ç”¨ SCALER.transform)
    data_scaled = SCALER.transform(new_df)

    # ğŸŒŸ ä¿®æ­£ç‚¹ï¼šå°†ç¼©æ”¾åçš„ NumPy æ•°ç»„é‡æ–°è½¬æ¢ä¸ºå¸¦æœ‰ç‰¹å¾åç§°çš„ DataFrame ğŸŒŸ
    data_scaled_df = pd.DataFrame(data_scaled, columns=FEATURE_COLUMNS)  # ç¡®ä¿æœ‰åˆ—å

    # 3. æ¨¡å‹é¢„æµ‹
    prediction_encoded = MODEL.predict(data_scaled_df)[0]  # ä¼ å…¥å¸¦æœ‰åˆ—åçš„ DataFrame
    # 4. é¢„æµ‹æ¦‚ç‡ (ç½®ä¿¡åº¦)
    prediction_proba = MODEL.predict_proba(data_scaled_df)[0]

    # 5. åå‘æ˜ å°„æ ‡ç­¾
    prediction_label = LE.inverse_transform([prediction_encoded])[0]

    # æ‰¾å‡ºæœ€é«˜æ¦‚ç‡å’Œå¯¹åº”æ ‡ç­¾
    max_proba = np.max(prediction_proba)

    # 6. è¿”å›ç»“æœ
    return {
        "status": "success",
        "predicted_label": prediction_label,
        "confidence": float(max_proba),
        "encoded_value": int(prediction_encoded)
    }


# ----------------------------------------------------------------------
# 3. ç¤ºä¾‹è°ƒç”¨ (æ¨¡æ‹Ÿç½‘ç«™ POST è¯·æ±‚)
# ----------------------------------------------------------------------

# âš ï¸ æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªåŒ…å« 78 ä¸ªç‰¹å¾å€¼çš„ç¤ºä¾‹æ•°æ®ã€‚
# å¿…é¡»ç¡®ä¿æ‚¨çš„ç½‘ç«™å‘å‡ºçš„æ•°æ®æ˜¯ç›¸åŒé•¿åº¦å’Œé¡ºåºã€‚
SAMPLE_RAW_DATA = [
    54865, 3, 2, 0, 12, 0, 6, 6, 6.0, 0.0, 0, 0, 0.0, 0.0, 4000000.0,
    666666.6667, 3.0, 0.0, 3, 3, 3, 3.0, 0.0, 3, 3, 0, 0.0, 0.0, 0, 0,
    0, 0, 0, 0, 40, 0, 666666.6667, 0.0, 6, 6, 6.0, 0.0, 0.0, 0, 0, 0,
    0, 1, 0, 0, 0, 0, 9.0, 6.0, 0.0, 40, 0, 0, 0, 0, 0, 0, 2, 12, 0, 0,
    33, -1, 1, 20, 0.0, 0.0, 0, 0, 0.0, 0.0, 0, 0
]

# è°ƒç”¨é¢„æµ‹å‡½æ•°
result = get_prediction(SAMPLE_RAW_DATA)

print("\n--- æ¨¡æ‹Ÿç½‘ç«™/API æ¥å£è¿”å›ç»“æœ ---")
print(pd.Series(result).to_json(indent=4))  # ä»¥ JSON æ ¼å¼æ‰“å°ç»“æœ

if result['status'] == 'success':
    if result['predicted_label'].upper() == 'BENIGN':
        print("\nğŸŸ¢ é¢„æµ‹ï¼šæµé‡æ­£å¸¸ (BENIGN)")
    else:
        print(f"\nğŸ”´ é¢„æµ‹ï¼šæ£€æµ‹åˆ°æ¶æ„æ”»å‡»ï¼ç±»å‹ä¸º {result['predicted_label']}")